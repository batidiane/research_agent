{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Research Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a concept agent that is inspired by my process of researching on a subject. <br>\n",
    "I also took some inspiration from BabyAGI (without tools) implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('./.env') \n",
    "import uuid\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embedding_model = \"text-embedding-ada-002\"\n",
    "gpt3t = \"gpt-3.5-turbo\"\n",
    "gpt4 = \"gpt-4\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=text_embedding_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_localdb = True\n",
    "\n",
    "SUPABASE_PASSWORD = os.environ['SUPABASE_PASSWORD']\n",
    "SUPABASE_DBUSER = os.environ['SUPABASE_DBUSER']\n",
    "SUPABASE_DATABASE = os.environ['SUPABASE_DATABASE']\n",
    "supabasedb_string = f\"postgresql://{SUPABASE_DBUSER}:{SUPABASE_PASSWORD}@db.doxggeyqopdnxfhseufq.supabase.co:5432/{SUPABASE_DATABASE}\"\n",
    "\n",
    "PGVECTOR_USER = os.environ['PGVECTOR_USER']\n",
    "PGVECTOR_PASSWORD = os.environ['PGVECTOR_PASSWORD']\n",
    "PGVECTOR_DATABASE = os.environ['PGVECTOR_DATABASE']\n",
    "localdb_string = f\"postgresql://{PGVECTOR_USER}:{PGVECTOR_PASSWORD}@localhost:5432/{PGVECTOR_DATABASE}\"\n",
    "\n",
    "connection_string = localdb_string if use_localdb else supabasedb_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main text store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.vectorstores.pgvector.PGVector'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import PGVector\n",
    "\n",
    "combined_text_store = PGVector(\n",
    "    collection_name='mahabharat_combined_text',\n",
    "    connection_string=connection_string,\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "print(type(combined_text_store))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supabase vector store for storing runs\n",
    "\n",
    "The supabase client here is not used as a vector store. \n",
    "I am only using it to save the runs data. \n",
    "You can remove it if you dont need it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase.client import Client, create_client\n",
    "from langchain.vectorstores import SupabaseVectorStore\n",
    "\n",
    "supabase_url = os.environ.get(\"SUPABASE_URL\")\n",
    "supabase_key = os.environ.get(\"SUPABASE_SERVICE_KEY\")\n",
    "supabase: Client = create_client(supabase_url, supabase_key)\n",
    "\n",
    "runs_store = SupabaseVectorStore(embedding=embeddings, client=supabase, table_name='runs',query_name=\"match_runs\")\n",
    "\n",
    "# ## Testing store\n",
    "# run_id = str(uuid.uuid4())\n",
    "# runs_store.add_texts(texts=[\"testing the store\"], metadatas=[{\"key\": \"value\"}], ids=[run_id])\n",
    "# matched_docs = runs_store.similarity_search_with_relevance_scores(\"testing store\", 1)\n",
    "# matched_docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function for converting question string to list of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split2Dict(question):\n",
    "    question = question.strip().split(\".\", 1)\n",
    "    question_dict = {question[0].strip(): question[-1].strip()}\n",
    "    return question_dict\n",
    "\n",
    "\n",
    "def result2DictOfQuestions(result: str):\n",
    "    questions = result.split(\"\\n\")\n",
    "    qdict = {}\n",
    "    for q in questions:\n",
    "        qdict = {**qdict, **split2Dict(q)}\n",
    "    return qdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question creator\n",
    "Generate new questions based on \n",
    "- `question` - Original question. This is important so that the pertinence to the original question is always maintained. Or else the context can diverge quickly into impertinent results.\n",
    "- `unanswered_questions`: So that the new questions do not overlap with the old ones.\n",
    "- `context`: The document found during the current run. So the questions are derived from the fresh information based on the current question being asked. \n",
    "- `num_questions`: Configurable hyper parameter.\n",
    "- `start_id`: This is passed so that the ids of the newly generated question do overlap with the current list. \n",
    "\n",
    "---\n",
    "#### Most pertinent Question chain\n",
    "Pick the most pertinent question out of the given list of questions <br>\n",
    "I am not using any additional context other than the `original_question` for decising the pertinence.\n",
    "\n",
    "---\n",
    "#### Retrieval QA\n",
    "This chain is used to answer the intermediate questions. The idea is to generate succinct answers which can be used as notes to finally answer the original question\n",
    "\n",
    "--- \n",
    "#### Result Analyser\n",
    "Not using this right now. I am not able to get this piece working well. So currently I will just run the agent for a fixed number of iterations and then compile the answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import all the chains. \n",
    "from chains.create_questions import QuestionCreationChain \n",
    "from chains.most_pertinent_question import MostPertinentQuestion\n",
    "from chains.retrieval_qa import retrieval_qa\n",
    "from chains.research_compiler import research_compiler\n",
    "\n",
    "## Model with parameters\n",
    "def language_model(model_name: str = gpt3t, temperature: float = 0, verbose: bool = False):\n",
    "    llm = ChatOpenAI(model_name=model_name, temperature=temperature)\n",
    "    return llm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Research Agent\n",
    "\n",
    "This is the final research Agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1m\n",
      " ------  Iteration 1 ------- \n",
      "\u001b[0m\u001b[0m\n",
      "\u001b[36;2m \n",
      "Current Question: Why did Kunti abandoned her first born??\n",
      " Current Answer: Kunti abandoned her first-born child because she had summoned the sun-god, Surya, using a mantra given to her by the rishi Durvasa. When Surya appeared and Kunti realized that she was going to have a child, she became fearful and regretful. However, Surya informed her that the mantra could not be undone, and she had to bear the consequences of her actions. Therefore, when the baby was born, Kunti put him in a basket and set him adrift in a river. The exact reason for her decision to abandon the child is not explicitly mentioned in the given context, but it can be inferred that Kunti did so out of fear, regret, and possibly a sense of responsibility towards her other sons and her position as a queen. \n",
      " \u001b[0m\u001b[0m\n",
      "\u001b[35;3m ** Unanswered Questions **\n",
      " '1. Why did Kunti use the mantra to summon Surya, the sun-god?'\n",
      "'2. What was the reason behind Kunti putting her first-born son in a basket and setting him adrift in a river?'\n",
      "'3. Why did Gandhari become angered when she heard about Kunti's child?'\n",
      "'4. What was the significance of Gandhari giving birth to a piece of flesh and Vyasadeva appearing?' \u001b[32;5m \n",
      "** Answered Questions **\n",
      "  \u001b[0m\u001b[0m\n",
      "\u001b[93m\u001b[1m \n",
      "Next Question I need to ask:  What was the reason behind Kunti putting her first-born son in a basket and setting him adrift in a river?\n",
      "Question Id: 2 \u001b[0m\u001b[0m\n",
      "\u001b[91m\u001b[1m\n",
      " ------  Iteration 2 ------- \n",
      "\u001b[0m\u001b[0m\n",
      "\u001b[36;2m \n",
      "Current Question:  What was the reason behind Kunti putting her first-born son in a basket and setting him adrift in a river?\n",
      " Current Answer: The reason behind Kunti putting her first-born son in a basket and setting him adrift in a river was due to fear of her relatives. As stated in the context, Kunti had conceived a child by the sun god Surya before her marriage to Pandu. However, she was ashamed of begetting a son while still unmarried, so she decided to hide the child. Kunti placed the baby in a basket and set it afloat on the river Ganges to ensure that her secret would not be discovered by her family. She wept bitterly and was afflicted with grief, but she had to let go of her son to protect herself and her reputation. The child, named Karna, was eventually found and raised by a carpenter and his wife. Kunti's decision to put her first-born son in a basket and set him adrift in the river was driven by her fear of the consequences and shame that would come from her relatives discovering her secret. \n",
      " \u001b[0m\u001b[0m\n",
      "\u001b[35;3m ** Unanswered Questions **\n",
      " '1. Why did Kunti use the mantra to summon Surya, the sun-god?'\n",
      "'3. Why did Gandhari become angered when she heard about Kunti's child?'\n",
      "'4. What was the significance of Gandhari giving birth to a piece of flesh and Vyasadeva appearing?'\n",
      "'5. How did Kunti's relatives react when they found out about her first-born son?'\n",
      "'6. What was the reaction of Adhiratha and Radha when they found the child in the basket?'\n",
      "'7. How did Karna's upbringing by Adhiratha and Radha influence his character and skills?'\n",
      "'8. Can you provide more details about the city of Champa and its ruler, who found and raised Karna?' \u001b[32;5m \n",
      "** Answered Questions **\n",
      " What was the reason behind Kunti putting her first-born son in a basket and setting him adrift in a river? \u001b[0m\u001b[0m\n",
      "\u001b[93m\u001b[1m \n",
      "Next Question I need to ask:  Why did Kunti abandon her first-born son?\n",
      "Question Id: 2 \u001b[0m\u001b[0m\n",
      "\u001b[91m\u001b[1m\n",
      " ------  Iteration 3 ------- \n",
      "\u001b[0m\u001b[0m\n",
      "\u001b[91m\u001b[1m\n",
      " ------ Max iterations reached.\u001b[0m\u001b[0m\n",
      "\u001b[1;37m\n",
      "Final Answer: \n",
      " The reason behind Kunti putting her first-born son in a basket and setting him adrift in a river was due to fear of her relatives. As stated in the context, Kunti had conceived a child by the sun god Surya before her marriage to Pandu. However, she was ashamed of begetting a son while still unmarried, so she decided to hide the child. Kunti placed the baby in a basket and set it afloat on the river Ganges to ensure that her secret would not be discovered by her family. She wept bitterly and was afflicted with grief, but she had to let go of her son to protect herself and her reputation. The child, named Karna, was eventually found and raised by a carpenter and his wife. Kunti's decision to put her first-born son in a basket and set him adrift in the river was driven by her fear of the consequences and shame that would come from her relatives discovering her secret.\n",
      "\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 23:40:26,654:INFO - HTTP Request: POST https://doxggeyqopdnxfhseufq.supabase.co/rest/v1/runs \"HTTP/1.1 201 Created\"\n"
     ]
    }
   ],
   "source": [
    "## First create a run id. \n",
    "run_id = str(uuid.uuid4())\n",
    "\n",
    "## Define scratchpad for keeping the run data\n",
    "scratchpad = {\n",
    "    'original_question': \"Why did Kunti abandoned her first born??\",\n",
    "    'unanswered_questions': {},\n",
    "    'answerpad': [],\n",
    "    'notes': [],\n",
    "    'current_documents': [],\n",
    "    'documents': [],\n",
    "    'answered_questions': [],\n",
    "}\n",
    "verbose = False\n",
    "first_run = True\n",
    "max_iterations = 3\n",
    "current_iteration = 0\n",
    "num_questions_per_iteration = 4\n",
    "question_creation_temperature = 0.5\n",
    "question_prioritisation_temperature = 0.5\n",
    "analyser_temperature = 0\n",
    "store = combined_text_store\n",
    "current_question_id = None\n",
    "\n",
    "\n",
    "## ---- The researcher -----\n",
    "while True: \n",
    "    current_iteration += 1\n",
    "\n",
    "    print(\"\\033[91m\\033[1m\" + f\"\\n ------  Iteration {current_iteration} ------- \\n\" + \"\\033[0m\\033[0m\")\n",
    "    if current_iteration >= max_iterations:\n",
    "        print(\"\\033[91m\\033[1m\" + f\"\\n ------ Max iterations reached.\" + \"\\033[0m\\033[0m\")\n",
    "        break\n",
    "    \n",
    "    ## 1. First run the retrieval_qa chain on current question\n",
    "    if first_run:\n",
    "        current_question = scratchpad['original_question']\n",
    "        current_answer, current_documents = retrieval_qa( \n",
    "            llm = language_model(temperature=0), \n",
    "            store = combined_text_store, \n",
    "            question = current_question, \n",
    "            verbose = verbose)\n",
    "        scratchpad['answerpad'] += [current_answer]\n",
    "        first_run = False\n",
    "    else:\n",
    "        current_answer, current_documents = retrieval_qa( \n",
    "            llm = language_model(temperature=0), \n",
    "            store = combined_text_store, \n",
    "            question = current_question, \n",
    "            verbose = verbose)\n",
    "        scratchpad['notes'] += [{'question': current_question, 'answer': current_answer}]\n",
    "\n",
    "    scratchpad['current_documents'] = current_documents\n",
    "    scratchpad['documents'] += current_documents\n",
    "    print(\n",
    "        \"\\033[36;2m\",\n",
    "        f\"\\nCurrent Question: {current_question}\\n\", \n",
    "        f\"Current Answer: {current_answer} \\n\",\n",
    "        \"\\033[0m\\033[0m\")\n",
    "\n",
    "    ## 2. Ask more questions based on current_answer as context\n",
    "    ## ----\n",
    "    start_id = (current_iteration-1)*num_questions_per_iteration + 1\n",
    "    question_creation_chain = QuestionCreationChain.from_llm(\n",
    "        llm = language_model(temperature=question_creation_temperature), \n",
    "        verbose=verbose\n",
    "        )\n",
    "    question_creation_response = question_creation_chain.run(\n",
    "        question=scratchpad['original_question'],\n",
    "        context=\"\\n\".join(list(map(lambda x: x.page_content, scratchpad['current_documents']))),\n",
    "        unanswered_questions=scratchpad['unanswered_questions'],\n",
    "        num_questions = num_questions_per_iteration,\n",
    "        start_id=start_id,\n",
    "    )\n",
    "    scratchpad['unanswered_questions'] = {\n",
    "        **scratchpad['unanswered_questions'], \n",
    "        **result2DictOfQuestions(result = question_creation_response)\n",
    "        }\n",
    "\n",
    "    if current_question_id:\n",
    "        scratchpad['answered_questions'] += [scratchpad['unanswered_questions'].pop(current_question_id)]\n",
    "        # Remove the current question here after generating the new questions so that the \n",
    "        # current question is not regenerated. \n",
    "       \n",
    "    print(\n",
    "        \"\\033[35;3m\",\n",
    "        \"** Unanswered Questions **\\n\",\n",
    "        \"\\n\".join(f\"'{key}. {value}'\" for key, value in scratchpad['unanswered_questions'].items()), \n",
    "        \"\\033[32;5m\",\n",
    "        \"\\n** Answered Questions **\\n\",\n",
    "        \"\\n\".join(scratchpad['answered_questions']),\n",
    "        \"\\033[0m\\033[0m\")\n",
    "    ### --- ###\n",
    "\n",
    "    ## 3. Find the most pertinent question to ask next \n",
    "    ## ----\n",
    "    find_next_question = MostPertinentQuestion.from_llm(\n",
    "        llm = language_model(temperature=question_prioritisation_temperature),\n",
    "        verbose = verbose\n",
    "        )\n",
    "    current_question = find_next_question.run(\n",
    "        original_question=scratchpad['original_question'],\n",
    "        unanswered_questions=\"\\n\".join(f\"'{key}. {value}',\" for key, value in scratchpad['unanswered_questions'].items()),\n",
    "    )\n",
    "\n",
    "    # print(\"next q response -->\", current_question)\n",
    "    # Calculate question id so it can be deleted in the next iteration\n",
    "    current_question_id = current_question.split('.', 1)[0]\n",
    "    current_question = current_question.split('.', 1)[-1]\n",
    "    print(\n",
    "        \"\\033[93m\\033[1m\", \n",
    "        f\"\\nNext Question I need to ask: {current_question}\\nQuestion Id: {current_question_id}\", \n",
    "        \"\\033[0m\\033[0m\")\n",
    "    ### --- ###\n",
    "\n",
    "\n",
    "\n",
    "## ----- The Compiler -----\n",
    "final_answer= research_compiler(\n",
    "    llm = language_model(temperature = analyser_temperature, verbose=True),\n",
    "    question = scratchpad['original_question'], \n",
    "    context = scratchpad['notes'], \n",
    "    prev_answer = scratchpad['answerpad'],\n",
    "    verbose = verbose)\n",
    "\n",
    "print(\"\\033[1;37m\" + f\"\\nFinal Answer: \\n {final_answer['text']}\\n\" + \"\\033[0m\\033[0m\")  \n",
    "\n",
    "## ----- Save the run data -----\n",
    "## If you do not need this, feel free to comment it out. \n",
    "_ = runs_store.add_texts(\n",
    "    texts=[scratchpad['original_question']], \n",
    "    metadatas=[{\n",
    "        'docs_metadata': [document.metadata for document in scratchpad['documents']], \n",
    "        'answer': final_answer['text'], \n",
    "        'context': final_answer['context']\n",
    "        }], \n",
    "    ids=[run_id])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenAI@3111",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
